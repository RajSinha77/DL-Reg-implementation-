{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtA2MEE0+S8DcDO3uyQ5ac",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RajSinha77/DL-Reg-implementation-/blob/main/DLReg_vs_L2_in_tiny_imagent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neb9U3lmUKQp",
        "outputId": "193cb78d-2220-4387-9935-1b05e4dc8fd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['image', 'label'],\n",
            "        num_rows: 100000\n",
            "    })\n",
            "    valid: Dataset({\n",
            "        features: ['image', 'label'],\n",
            "        num_rows: 10000\n",
            "    })\n",
            "})\n",
            "Available splits: ['train', 'valid']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Define constants\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 25\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# Load the Tiny-ImageNet dataset from Hugging Face\n",
        "dataset = load_dataset('zh-plus/tiny-imagenet')\n",
        "\n",
        "# Print the dataset structure to check available splits\n",
        "print(dataset)\n",
        "\n",
        "# Identify the correct splits\n",
        "available_splits = list(dataset.keys())\n",
        "print(f\"Available splits: {available_splits}\")\n",
        "\n",
        "train_split = 'train' if 'train' in available_splits else available_splits[0]\n",
        "val_split = 'validation' if 'validation' in available_splits else 'val' if 'val' in available_splits else available_splits[1]\n",
        "\n",
        "# Custom dataset class to handle Hugging Face dataset\n",
        "class TinyImageNetDataset(Dataset):\n",
        "    def __init__(self, hf_dataset, transform=None):\n",
        "        self.dataset = hf_dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.dataset[idx]\n",
        "        image = sample['image']\n",
        "        label = sample['label']\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Transformations for the Tiny-ImageNet dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Lambda(lambda x: x.convert(\"RGB\") if x.mode != \"RGB\" else x),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Prepare the dataset and dataloaders\n",
        "train_dataset = TinyImageNetDataset(dataset[train_split], transform=transform)\n",
        "val_dataset = TinyImageNetDataset(dataset[val_split], transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Define the models\n",
        "resnet152 = models.resnet152(pretrained=True)\n",
        "densenet = models.densenet121(pretrained=True)\n",
        "\n",
        "# Modify the final layers to fit Tiny-ImageNet classes\n",
        "num_ftrs_resnet = resnet152.fc.in_features\n",
        "resnet152.fc = nn.Linear(num_ftrs_resnet, 200)\n",
        "\n",
        "num_ftrs_densenet = densenet.classifier.in_features\n",
        "densenet.classifier = nn.Linear(num_ftrs_densenet, 200)\n",
        "\n",
        "# Define DL-Regularization\n",
        "class DLRegularization(nn.Module):\n",
        "    def __init__(self, model, lambda_reg=0.001):\n",
        "        super(DLRegularization, self).__init__()\n",
        "        self.model = model\n",
        "        self.lambda_reg = lambda_reg\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.model(x)\n",
        "        return output\n",
        "\n",
        "    def dl_reg_loss(self, x, output):\n",
        "        Z = nn.Linear(x.size(1), output.size(1), bias=False).to(x.device)\n",
        "        reg_loss = torch.norm(Z(x) - output) ** 2\n",
        "        return self.lambda_reg * reg_loss\n",
        "\n",
        "# Training function\n",
        "def train_model(model, criterion, optimizer, num_epochs=NUM_EPOCHS, dl_regularizer=None):\n",
        "    model.train()\n",
        "    train_acc = []\n",
        "    val_acc = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_corrects = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            if dl_regularizer:\n",
        "                reg_loss = dl_regularizer.dl_reg_loss(inputs, outputs)\n",
        "                loss += reg_loss\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_acc = running_corrects.double() / len(train_dataset)\n",
        "        train_acc.append(epoch_acc.item())\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_corrects = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_val_acc = val_corrects.double() / len(val_dataset)\n",
        "        val_acc.append(epoch_val_acc.item())\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Train Acc: {epoch_acc.item()}, Val Acc: {epoch_val_acc.item()}')\n",
        "\n",
        "    return train_acc, val_acc\n",
        "\n",
        "# Initialize device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Experiment with L2 regularization\n",
        "resnet152 = resnet152.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet152.parameters(), lr=LEARNING_RATE, weight_decay=0.001)\n",
        "train_acc_l2, val_acc_l2 = train_model(resnet152, criterion, optimizer)\n",
        "\n",
        "# Experiment with DL-Regularization\n",
        "densenet = densenet.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(densenet.parameters(), lr=LEARNING_RATE)\n",
        "dl_regularizer = DLRegularization(densenet, lambda_reg=0.001)\n",
        "train_acc_dl, val_acc_dl = train_model(densenet, criterion, optimizer, dl_regularizer=dl_regularizer)\n",
        "\n",
        "# Plotting the results\n",
        "epochs = range(1, NUM_EPOCHS + 1)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_acc_l2, label='L2 Regularization')\n",
        "plt.plot(epochs, train_acc_dl, label='DL-Regularization')\n",
        "plt.title('Training Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, val_acc_l2, label='L2 Regularization')\n",
        "plt.plot(epochs, val_acc_dl, label='DL-Regularization')\n",
        "plt.title('Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_3QXmZaVYBy",
        "outputId": "ac6c78f3-1a6d-4d3c-e112-bcf6110d3f21"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['image', 'label'],\n",
            "        num_rows: 100000\n",
            "    })\n",
            "    valid: Dataset({\n",
            "        features: ['image', 'label'],\n",
            "        num_rows: 10000\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    }
  ]
}